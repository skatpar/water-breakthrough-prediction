{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics-Informed Water Breakthrough Prediction\n",
    "\n",
    "This notebook demonstrates the **end-to-end pipeline** for training and evaluating a\n",
    "Physics-Informed Neural Network (PINN) that predicts water breakthrough in oil reservoirs.\n",
    "\n",
    "The model combines:\n",
    "- **LSTM temporal encoder** for sequential production data\n",
    "- **Buckley-Leverett physics branch** (fractional flow, Corey relative permeability)\n",
    "- **Data-driven MLP branch** for residual patterns\n",
    "- **Log-normal survival head** for time-to-breakthrough uncertainty (P10/P50/P90)\n",
    "- **Breakthrough classifier** (binary detection)\n",
    "\n",
    "### Outline\n",
    "1. [Setup & Imports](#1-setup--imports)\n",
    "2. [Configuration](#2-configuration)\n",
    "3. [Data Loading & Feature Engineering](#3-data-loading--feature-engineering)\n",
    "4. [Exploratory Data Analysis](#4-exploratory-data-analysis)\n",
    "5. [Dataset Preparation (Sequences & Splits)](#5-dataset-preparation)\n",
    "6. [Model Architecture](#6-model-architecture)\n",
    "7. [Training](#7-training)\n",
    "8. [Evaluation Metrics](#8-evaluation-metrics)\n",
    "9. [Prediction Visualizations](#9-prediction-visualizations)\n",
    "10. [Physics Interpretation](#10-physics-interpretation)\n",
    "11. [Survival Analysis](#11-survival-analysis)\n",
    "12. [Save & Export](#12-save--export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Imports\n",
    "\n",
    "Import all required libraries and the project source modules.\n",
    "The project expects `torch`, `numpy`, `pandas`, `matplotlib`, `scikit-learn`, and `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure the project root is on the Python path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data_loader import (\n",
    "    build_dataset,\n",
    "    generate_synthetic_volve_data,\n",
    "    compute_water_cut,\n",
    "    compute_cumulative_production,\n",
    "    compute_time_features,\n",
    "    detect_breakthrough,\n",
    "    filter_production_wells,\n",
    "    VOLVE_COLUMNS,\n",
    ")\n",
    "from src.model import PhysicsInformedBreakthroughModel\n",
    "from src.train import train_model, TrainConfig\n",
    "from src.evaluate import (\n",
    "    evaluate_model,\n",
    "    print_metrics,\n",
    "    plot_training_history,\n",
    "    plot_predictions,\n",
    "    plot_fractional_flow_curve,\n",
    "    plot_survival_analysis,\n",
    ")\n",
    "from src.physics import compute_breakthrough_time_analytical\n",
    "from src.survival import compute_survival_function, compute_hazard_function, compute_percentiles\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({\"figure.dpi\": 120, \"font.size\": 11})\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Project root:    {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Configuration\n",
    "\n",
    "Set the random seed for reproducibility, choose a device, and define training\n",
    "hyperparameters. Modify these values to experiment.\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `SEED` | Random seed for reproducibility |\n",
    "| `SEQ_LENGTH` | Number of time steps in each input sequence |\n",
    "| `TEST_FRACTION` | Fraction of data held out for testing (temporal split) |\n",
    "| `DATA_PATH` | Path to Volve CSV, or `None` for synthetic data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reproducibility ---\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# --- Device ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- Data ---\n",
    "DATA_PATH = None          # Set to a CSV path to use real Volve data\n",
    "SEQ_LENGTH = 30           # LSTM input window\n",
    "TEST_FRACTION = 0.2       # 80/20 temporal split\n",
    "\n",
    "# --- Training hyperparameters ---\n",
    "config = TrainConfig(\n",
    "    epochs=200,\n",
    "    batch_size=64,\n",
    "    learning_rate=1e-3,\n",
    "    hidden_size=64,\n",
    "    lstm_layers=2,\n",
    "    dropout=0.1,\n",
    "    physics_anneal_end=0.1,\n",
    "    lambda_survival=0.2,\n",
    "    model_save_path=str(PROJECT_ROOT / \"models\" / \"best_model.pt\"),\n",
    ")\n",
    "\n",
    "SAVE_DIR = str(PROJECT_ROOT / \"results\")\n",
    "print(f\"Results will be saved to: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Loading & Feature Engineering\n",
    "\n",
    "The pipeline supports two modes:\n",
    "- **Real data**: Provide a path to the [Volve production CSV](https://www.kaggle.com/datasets/lamyalbert/volve-production-data).\n",
    "- **Synthetic data**: Auto-generated if no CSV is provided. Mimics realistic decline\n",
    "  curves, sigmoid water breakthrough, and pressure dynamics across 5 wells over 1500 days.\n",
    "\n",
    "Feature engineering steps performed:\n",
    "1. **Water cut** computation: `water / (oil + water)`\n",
    "2. **Cumulative production** per well\n",
    "3. **Days on production** (time feature)\n",
    "4. **Breakthrough labelling**: first time water cut exceeds threshold for 3 consecutive days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate or load raw data\n",
    "if DATA_PATH and Path(DATA_PATH).exists():\n",
    "    from src.data_loader import load_volve_data\n",
    "    df_raw = load_volve_data(DATA_PATH)\n",
    "    df_raw = filter_production_wells(df_raw)\n",
    "    print(f\"Loaded real Volve data: {len(df_raw)} rows\")\n",
    "else:\n",
    "    df_raw = generate_synthetic_volve_data(n_wells=5, n_days=1500, seed=SEED)\n",
    "    print(f\"Generated synthetic data: {len(df_raw)} rows\")\n",
    "\n",
    "# Feature engineering\n",
    "df = compute_water_cut(df_raw.copy())\n",
    "df = compute_cumulative_production(df)\n",
    "df = compute_time_features(df)\n",
    "df = detect_breakthrough(df)\n",
    "\n",
    "print(f\"Wells: {df[VOLVE_COLUMNS['well']].nunique()}\")\n",
    "print(f\"Date range: {df[VOLVE_COLUMNS['date']].min()} to {df[VOLVE_COLUMNS['date']].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Exploratory Data Analysis\n",
    "\n",
    "Visualize key production trends before training to understand the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Water Cut Over Time per Well\n",
    "\n",
    "The sigmoid-like rise in water cut after breakthrough is the core signal the model\n",
    "must capture. The vertical dashed line marks the labelled breakthrough point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "well_col = VOLVE_COLUMNS[\"well\"]\n",
    "\n",
    "# Water cut over time\n",
    "ax = axes[0]\n",
    "for well_id, group in df.groupby(well_col):\n",
    "    ax.plot(group[\"DAYS_ON_PRODUCTION\"], group[\"WATER_CUT\"],\n",
    "            label=f\"Well {well_id}\", linewidth=0.9, alpha=0.8)\n",
    "ax.set_xlabel(\"Days on Production\")\n",
    "ax.set_ylabel(\"Water Cut\")\n",
    "ax.set_title(\"Water Cut Evolution per Well\")\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Oil rate decline\n",
    "ax = axes[1]\n",
    "for well_id, group in df.groupby(well_col):\n",
    "    ax.plot(group[\"DAYS_ON_PRODUCTION\"],\n",
    "            group[VOLVE_COLUMNS[\"bore_oil_vol\"]],\n",
    "            label=f\"Well {well_id}\", linewidth=0.9, alpha=0.8)\n",
    "ax.set_xlabel(\"Days on Production\")\n",
    "ax.set_ylabel(\"Oil Rate (Sm3/day)\")\n",
    "ax.set_title(\"Oil Rate Decline per Well\")\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Pressure & Cumulative Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Downhole pressure\n",
    "ax = axes[0]\n",
    "for well_id, group in df.groupby(well_col):\n",
    "    ax.plot(group[\"DAYS_ON_PRODUCTION\"],\n",
    "            group[VOLVE_COLUMNS[\"avg_downhole_press\"]],\n",
    "            label=f\"Well {well_id}\", linewidth=0.9, alpha=0.8)\n",
    "ax.set_xlabel(\"Days on Production\")\n",
    "ax.set_ylabel(\"Downhole Pressure (bar)\")\n",
    "ax.set_title(\"Average Downhole Pressure\")\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative liquid\n",
    "ax = axes[1]\n",
    "for well_id, group in df.groupby(well_col):\n",
    "    ax.plot(group[\"DAYS_ON_PRODUCTION\"], group[\"CUM_LIQUID\"],\n",
    "            label=f\"Well {well_id}\", linewidth=0.9, alpha=0.8)\n",
    "ax.set_xlabel(\"Days on Production\")\n",
    "ax.set_ylabel(\"Cumulative Liquid (Sm3)\")\n",
    "ax.set_title(\"Cumulative Liquid Production\")\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Breakthrough Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_counts = df[\"BREAKTHROUGH\"].value_counts().sort_index()\n",
    "print(\"Breakthrough label distribution:\")\n",
    "print(f\"  Pre-breakthrough  (0): {bt_counts.get(0.0, 0):,}\")\n",
    "print(f\"  Post-breakthrough (1): {bt_counts.get(1.0, 0):,}\")\n",
    "print(f\"  Ratio: {bt_counts.get(1.0, 0) / len(df):.1%} post-breakthrough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Dataset Preparation\n",
    "\n",
    "The `build_dataset` function performs the full pipeline:\n",
    "1. Feature scaling with `MinMaxScaler`\n",
    "2. Sliding-window **sequence creation** (length = `SEQ_LENGTH`)\n",
    "3. **Temporal train/test split** (no shuffling, preserves time order)\n",
    "4. Conversion to **PyTorch tensors**\n",
    "5. Preparation of **physics inputs** and **survival targets** (time-to-event, censoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(\n",
    "    data_path=DATA_PATH,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    test_fraction=TEST_FRACTION,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset summary:\")\n",
    "print(f\"  Training samples:  {dataset['X_train'].shape[0]:,}\")\n",
    "print(f\"  Test samples:      {dataset['X_test'].shape[0]:,}\")\n",
    "print(f\"  Sequence length:   {dataset['seq_length']}\")\n",
    "print(f\"  Input features:    {dataset['n_features']}\")\n",
    "print(f\"  Wells:             {dataset['well_names']}\")\n",
    "print(f\"  X_train shape:     {tuple(dataset['X_train'].shape)}\")\n",
    "print(f\"  y_train shape:     {tuple(dataset['y_train'].shape)}\")\n",
    "print(f\"  tte_train shape:   {tuple(dataset['tte_train'].shape)}\")\n",
    "print(f\"  event_train shape: {tuple(dataset['event_train'].shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Model Architecture\n",
    "\n",
    "The `PhysicsInformedBreakthroughModel` has the following structure:\n",
    "\n",
    "```\n",
    "Input (batch, seq_len, n_features)\n",
    "  |-> LSTM Temporal Encoder -> h (batch, hidden_size)\n",
    "       |\n",
    "       |-> Physics Branch: h -> Saturation MLP -> S_w -> Corey Rel-Perm -> f_w(physics)\n",
    "       |-> Data Branch:    h -> MLP -> f_w(data)\n",
    "       |-> Gate Network:   h -> sigmoid gate alpha\n",
    "       |\n",
    "       |-> Blended water_cut = alpha * f_w(physics) + (1-alpha) * f_w(data)\n",
    "       |-> Breakthrough Classifier: h -> logit\n",
    "       |-> Survival Head: h -> (mu, sigma) for LogNormal time-to-breakthrough\n",
    "```\n",
    "\n",
    "Learnable physics parameters: `S_wc`, `S_or`, `kr_w_max`, `kr_o_max`, `n_w`, `n_o`,\n",
    "`mu_w`, `mu_o`, `porosity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model to inspect its architecture\n",
    "model_preview = PhysicsInformedBreakthroughModel(\n",
    "    n_features=dataset[\"n_features\"],\n",
    "    hidden_size=config.hidden_size,\n",
    "    lstm_layers=config.lstm_layers,\n",
    "    dropout=config.dropout,\n",
    ").to(DEVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model_preview.parameters())\n",
    "trainable_params = sum(p.numel() for p in model_preview.parameters() if p.requires_grad)\n",
    "physics_params = sum(\n",
    "    p.numel() for n, p in model_preview.named_parameters()\n",
    "    if any(k in n for k in [\"rel_perm\", \"log_mu\", \"log_porosity\"])\n",
    ")\n",
    "\n",
    "print(f\"Total parameters:    {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Physics parameters:  {physics_params:,}\")\n",
    "print(f\"\\nInitial physics parameters:\")\n",
    "for k, v in model_preview.get_physics_parameters().items():\n",
    "    print(f\"  {k:12s}: {v:.4f}\")\n",
    "\n",
    "del model_preview  # free memory before training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Training\n",
    "\n",
    "The training loop uses a **composite loss function** with six components:\n",
    "\n",
    "| Loss Term | Weight | Purpose |\n",
    "|-----------|--------|---------|\n",
    "| Data MSE | 1.0 | Match observed water cut |\n",
    "| Physics fit | annealed 0.01 -> 0.1 | Physics branch matches data |\n",
    "| Monotonicity | 0.05 | Penalize non-physical water cut decreases |\n",
    "| Breakthrough BCE | 0.3 | Binary breakthrough detection |\n",
    "| Material balance | 0.05 | Physics/data branch consistency |\n",
    "| Survival NLL | 0.2 | Log-normal time-to-breakthrough |\n",
    "\n",
    "Optimization features:\n",
    "- **AdamW** with separate learning rates (physics params get 0.1x)\n",
    "- **ReduceLROnPlateau** scheduler\n",
    "- **Gradient clipping** (max norm = 1.0)\n",
    "- **Early stopping** (patience = 30 epochs)\n",
    "- **Physics weight annealing** over first 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_model(dataset, config, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Training Curves\n",
    "\n",
    "Inspect total loss, data-only loss, physics weight schedule, and learned parameter evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Total loss\n",
    "ax = axes[0, 0]\n",
    "ax.plot(history[\"train_loss\"], label=\"Train\", linewidth=1.5)\n",
    "ax.plot(history[\"val_loss\"], label=\"Validation\", linewidth=1.5)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Total Loss\")\n",
    "ax.set_title(\"Total Loss (all components)\")\n",
    "ax.legend()\n",
    "ax.set_yscale(\"log\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Data loss\n",
    "ax = axes[0, 1]\n",
    "ax.plot(history[\"train_data_loss\"], label=\"Train\", linewidth=1.5)\n",
    "ax.plot(history[\"val_data_loss\"], label=\"Validation\", linewidth=1.5)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_title(\"Data Loss (Water Cut MSE)\")\n",
    "ax.legend()\n",
    "ax.set_yscale(\"log\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Physics weight annealing\n",
    "ax = axes[1, 0]\n",
    "ax.plot(history[\"physics_weight\"], linewidth=1.5, color=\"green\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Weight\")\n",
    "ax.set_title(\"Physics Loss Weight (Annealing Schedule)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Learned physics parameters\n",
    "ax = axes[1, 1]\n",
    "params_hist = history.get(\"learned_params\", [])\n",
    "if params_hist:\n",
    "    epochs = range(len(params_hist))\n",
    "    ax.plot(epochs, [p[\"s_wc\"] for p in params_hist], label=\"S_wc\")\n",
    "    ax.plot(epochs, [p[\"s_or\"] for p in params_hist], label=\"S_or\")\n",
    "    ax.plot(epochs, [p[\"n_w\"] / 6 for p in params_hist], label=\"n_w/6\")\n",
    "    ax.plot(epochs, [p[\"n_o\"] / 6 for p in params_hist], label=\"n_o/6\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    ax.set_title(\"Learned Physics Parameters\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Evaluation Metrics\n",
    "\n",
    "Evaluate the trained model on the held-out **test set** (temporal split).\n",
    "\n",
    "Metrics computed:\n",
    "- **Regression**: MAE, RMSE, R-squared (scaled and original)\n",
    "- **Classification**: Accuracy, Precision, Recall, F1 for breakthrough detection\n",
    "- **Survival**: P10/P50/P90 percentile statistics and 80% calibration interval\n",
    "- **Physics gate**: Mean gate value (1 = physics-dominated, 0 = data-dominated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_model(model, dataset, DEVICE)\n",
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Prediction Visualizations\n",
    "\n",
    "Compare actual vs predicted water cut on the test set, and inspect how the\n",
    "physics-data gating mechanism allocates predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(dataset[\"X_test\"].to(DEVICE))\n",
    "\n",
    "y_true = dataset[\"y_test\"].cpu().numpy().flatten()\n",
    "y_pred = outputs[\"water_cut\"].cpu().numpy().flatten()\n",
    "y_physics = outputs[\"water_cut_physics\"].cpu().numpy().flatten()\n",
    "y_data = outputs[\"water_cut_data\"].cpu().numpy().flatten()\n",
    "gate = outputs[\"gate_value\"].cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Water Cut: Actual vs Predicted Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = min(500, len(y_true))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.plot(range(n_plot), y_true[:n_plot], label=\"Actual\", linewidth=1.2, alpha=0.8)\n",
    "ax.plot(range(n_plot), y_pred[:n_plot], label=\"Predicted (blended)\",\n",
    "        linewidth=1.2, alpha=0.8)\n",
    "ax.plot(range(n_plot), y_physics[:n_plot], label=\"Physics only\",\n",
    "        linewidth=0.8, alpha=0.5, linestyle=\"--\")\n",
    "ax.plot(range(n_plot), y_data[:n_plot], label=\"Data only\",\n",
    "        linewidth=0.8, alpha=0.5, linestyle=\":\")\n",
    "ax.set_xlabel(\"Sample Index\")\n",
    "ax.set_ylabel(\"Water Cut (scaled)\")\n",
    "ax.set_title(\"Test Set: Actual vs Predicted Water Cut\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Scatter Plot & Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter\n",
    "ax = axes[0]\n",
    "ax.scatter(y_true, y_pred, alpha=0.3, s=10)\n",
    "ax.plot([0, 1], [0, 1], \"r--\", linewidth=1.5, label=\"Perfect\")\n",
    "ax.set_xlabel(\"Actual Water Cut\")\n",
    "ax.set_ylabel(\"Predicted Water Cut\")\n",
    "ax.set_title(f\"Prediction Scatter (R² = {metrics['r2']:.4f})\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Residual distribution\n",
    "ax = axes[1]\n",
    "residuals = y_pred - y_true\n",
    "ax.hist(residuals, bins=50, alpha=0.7, edgecolor=\"black\", linewidth=0.5)\n",
    "ax.axvline(x=0, color=\"red\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Residual (Predicted - Actual)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(f\"Residual Distribution (mean={residuals.mean():.4f}, std={residuals.std():.4f})\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Physics-Data Gate & Breakthrough Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gate\n",
    "ax = axes[0]\n",
    "ax.plot(range(n_plot), gate[:n_plot], linewidth=1, color=\"purple\")\n",
    "ax.set_xlabel(\"Sample Index\")\n",
    "ax.set_ylabel(\"Gate Value\")\n",
    "ax.set_title(\"Physics vs Data Gate (1=Physics, 0=Data)\")\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Breakthrough\n",
    "ax = axes[1]\n",
    "bt_true = dataset[\"bt_test\"].cpu().numpy()\n",
    "bt_logit = outputs[\"breakthrough_logit\"].cpu().numpy().flatten()\n",
    "bt_prob = 1 / (1 + np.exp(-bt_logit))\n",
    "ax.plot(range(n_plot), bt_true[:n_plot], label=\"Actual\", linewidth=1.2, alpha=0.8)\n",
    "ax.plot(range(n_plot), bt_prob[:n_plot], label=\"Predicted probability\",\n",
    "        linewidth=1.2, alpha=0.8)\n",
    "ax.axhline(y=0.5, color=\"r\", linestyle=\"--\", alpha=0.5, label=\"Decision boundary\")\n",
    "ax.set_xlabel(\"Sample Index\")\n",
    "ax.set_ylabel(\"Breakthrough\")\n",
    "ax.set_title(\"Breakthrough Detection\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Physics Interpretation\n",
    "\n",
    "One of the key advantages of a PINN is **interpretability**: the model learns physically\n",
    "meaningful reservoir parameters. Here we visualize the learned Buckley-Leverett\n",
    "fractional flow curve and Corey relative permeability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Learned Reservoir Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.get_physics_parameters()\n",
    "\n",
    "print(\"Learned Reservoir Parameters:\")\n",
    "print(f\"  Connate water saturation (S_wc):  {params['s_wc']:.4f}\")\n",
    "print(f\"  Residual oil saturation (S_or):   {params['s_or']:.4f}\")\n",
    "print(f\"  Max water rel-perm (kr_w_max):    {params['kr_w_max']:.4f}\")\n",
    "print(f\"  Max oil rel-perm (kr_o_max):      {params['kr_o_max']:.4f}\")\n",
    "print(f\"  Corey water exponent (n_w):       {params['n_w']:.4f}\")\n",
    "print(f\"  Corey oil exponent (n_o):         {params['n_o']:.4f}\")\n",
    "print(f\"  Water viscosity (mu_w):           {params['mu_w']:.4f} cP\")\n",
    "print(f\"  Oil viscosity (mu_o):             {params['mu_o']:.4f} cP\")\n",
    "print(f\"  Mobility ratio (M):               {params['mu_w']/params['mu_o']:.4f}\")\n",
    "print(f\"  Porosity:                         {params['porosity']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Fractional Flow Curve & Welge Tangent\n",
    "\n",
    "The Buckley-Leverett fractional flow curve `f_w(S_w)` determines the displacement\n",
    "efficiency. The Welge tangent from `(S_wc, 0)` identifies the shock front saturation\n",
    "and breakthrough time in pore volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytical solution with learned parameters\n",
    "analytical = compute_breakthrough_time_analytical(\n",
    "    s_wc=params[\"s_wc\"], s_or=params[\"s_or\"],\n",
    "    mu_w=params[\"mu_w\"], mu_o=params[\"mu_o\"],\n",
    "    n_w=params[\"n_w\"], n_o=params[\"n_o\"],\n",
    ")\n",
    "\n",
    "print(f\"Analytical Buckley-Leverett Solution:\")\n",
    "print(f\"  Breakthrough time: {analytical['breakthrough_pv']:.3f} pore volumes\")\n",
    "print(f\"  Front saturation:  {analytical['s_w_front']:.3f}\")\n",
    "print(f\"  Avg saturation behind front: {analytical['s_w_avg_behind_front']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute relative permeability from model\n",
    "model.eval()\n",
    "s_w_tensor = torch.linspace(params[\"s_wc\"], 1 - params[\"s_or\"], 200).unsqueeze(1)\n",
    "with torch.no_grad():\n",
    "    f_w_learned = model.physics_branch.fractional_flow(s_w_tensor)\n",
    "    kr_w, kr_o = model.physics_branch.rel_perm(s_w_tensor)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Fractional flow\n",
    "ax = axes[0]\n",
    "ax.plot(analytical[\"saturation_grid\"], analytical[\"fractional_flow_curve\"],\n",
    "        \"b-\", linewidth=2, label=\"f_w(S_w)\")\n",
    "ax.axvline(x=analytical[\"s_w_front\"], color=\"r\", linestyle=\"--\", alpha=0.7,\n",
    "           label=f\"Front S_wf={analytical['s_w_front']:.3f}\")\n",
    "# Welge tangent\n",
    "slope = analytical[\"f_w_front\"] / (analytical[\"s_w_front\"] - params[\"s_wc\"])\n",
    "s_tang = np.linspace(params[\"s_wc\"], analytical[\"s_w_front\"], 50)\n",
    "ax.plot(s_tang, slope * (s_tang - params[\"s_wc\"]), \"g--\", linewidth=1.5,\n",
    "        label=\"Welge tangent\")\n",
    "ax.set_xlabel(\"Water Saturation S_w\")\n",
    "ax.set_ylabel(\"Fractional Flow f_w\")\n",
    "ax.set_title(\"Buckley-Leverett Fractional Flow\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Relative permeability\n",
    "ax = axes[1]\n",
    "s_np = s_w_tensor.numpy().flatten()\n",
    "ax.plot(s_np, kr_w.numpy().flatten(), \"b-\", linewidth=2, label=\"kr_w\")\n",
    "ax.plot(s_np, kr_o.numpy().flatten(), \"r-\", linewidth=2, label=\"kr_o\")\n",
    "ax.set_xlabel(\"Water Saturation S_w\")\n",
    "ax.set_ylabel(\"Relative Permeability\")\n",
    "ax.set_title(f\"Corey Rel-Perm (n_w={params['n_w']:.2f}, n_o={params['n_o']:.2f})\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# df/dS\n",
    "ax = axes[2]\n",
    "ax.plot(analytical[\"saturation_grid\"], analytical[\"df_ds\"], \"b-\", linewidth=2)\n",
    "ax.axvline(x=analytical[\"s_w_front\"], color=\"r\", linestyle=\"--\", alpha=0.7,\n",
    "           label=f\"BT at {analytical['breakthrough_pv']:.2f} PV\")\n",
    "ax.set_xlabel(\"Water Saturation S_w\")\n",
    "ax.set_ylabel(\"df_w/dS_w\")\n",
    "ax.set_title(\"Fractional Flow Derivative (Shock Speed)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Survival Analysis\n",
    "\n",
    "The log-normal survival head predicts a **distribution** over time-to-breakthrough for\n",
    "each sample, providing:\n",
    "- **P10** (optimistic/early estimate)\n",
    "- **P50** (median estimate)\n",
    "- **P90** (conservative/late estimate)\n",
    "\n",
    "This is critical for risk-based decision-making in reservoir management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Percentile Predictions with Uncertainty Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = outputs[\"survival_percentiles\"]\n",
    "p10 = percentiles[\"P10\"].cpu().numpy().flatten()\n",
    "p50 = percentiles[\"P50\"].cpu().numpy().flatten()\n",
    "p90 = percentiles[\"P90\"].cpu().numpy().flatten()\n",
    "\n",
    "tte_true = dataset[\"tte_test\"].cpu().numpy().flatten()\n",
    "event_true = dataset[\"event_test\"].cpu().numpy().flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "n_surv = min(500, len(p50))\n",
    "x_range = range(n_surv)\n",
    "\n",
    "ax.fill_between(x_range, p10[:n_surv], p90[:n_surv],\n",
    "                alpha=0.3, color=\"steelblue\", label=\"P10-P90 interval\")\n",
    "ax.plot(x_range, p50[:n_surv], color=\"steelblue\", linewidth=1.5, label=\"P50 (median)\")\n",
    "\n",
    "observed = event_true[:n_surv] == 1.0\n",
    "if observed.any():\n",
    "    ax.scatter(np.where(observed)[0], tte_true[:n_surv][observed],\n",
    "              s=8, color=\"red\", alpha=0.6, label=\"Observed BT time\", zorder=5)\n",
    "\n",
    "ax.set_xlabel(\"Sample Index\")\n",
    "ax.set_ylabel(\"Time to Breakthrough (normalized)\")\n",
    "ax.set_title(\"Predicted Time-to-Breakthrough with Uncertainty\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSurvival Percentile Summary (test set):\")\n",
    "print(f\"  P10 mean: {p10.mean():.4f} (+/- {p10.std():.4f})\")\n",
    "print(f\"  P50 mean: {p50.mean():.4f} (+/- {p50.std():.4f})\")\n",
    "print(f\"  P90 mean: {p90.mean():.4f} (+/- {p90.std():.4f})\")\n",
    "if \"survival_calibration_80\" in metrics:\n",
    "    print(f\"  80% interval calibration: {metrics['survival_calibration_80']:.1%} (ideal: 80%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Survival Curve & Hazard Function\n",
    "\n",
    "The survival function `S(t) = P(T > t)` shows the probability of **not** having\n",
    "broken through by time `t`. The hazard function `h(t) = f(t)/S(t)` gives the\n",
    "instantaneous breakthrough rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_vals = outputs[\"survival_mu\"].cpu()\n",
    "sigma_vals = outputs[\"survival_sigma\"].cpu()\n",
    "mu_mean = mu_vals.mean()\n",
    "sigma_mean = sigma_vals.mean()\n",
    "\n",
    "t_grid = torch.linspace(0.01, 2.0, 200)\n",
    "survival = compute_survival_function(\n",
    "    mu_mean.unsqueeze(0), sigma_mean.unsqueeze(0), t_grid\n",
    ").numpy().flatten()\n",
    "hazard = compute_hazard_function(\n",
    "    mu_mean.unsqueeze(0), sigma_mean.unsqueeze(0), t_grid\n",
    ").numpy().flatten()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Survival curve\n",
    "ax = axes[0]\n",
    "ax.plot(t_grid.numpy(), survival, color=\"steelblue\", linewidth=2)\n",
    "for pval, label, ls in [(0.90, \"P10\", \"--\"), (0.50, \"P50\", \"-\"), (0.10, \"P90\", \"--\")]:\n",
    "    ax.axhline(y=pval, color=\"gray\", linestyle=ls, alpha=0.4)\n",
    "    idx = np.searchsorted(-survival, -pval)\n",
    "    if idx < len(t_grid):\n",
    "        t_pct = t_grid[idx].item()\n",
    "        ax.axvline(x=t_pct, color=\"gray\", linestyle=ls, alpha=0.4)\n",
    "        ax.annotate(label, xy=(t_pct, pval), xytext=(t_pct + 0.05, pval + 0.03), fontsize=9)\n",
    "ax.set_xlabel(\"Time (normalized)\")\n",
    "ax.set_ylabel(\"Survival Probability S(t)\")\n",
    "ax.set_title(\"Mean Survival Curve\")\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hazard function\n",
    "ax = axes[1]\n",
    "ax.plot(t_grid.numpy(), hazard, color=\"darkred\", linewidth=2)\n",
    "ax.set_xlabel(\"Time (normalized)\")\n",
    "ax.set_ylabel(\"Hazard Rate h(t)\")\n",
    "ax.set_title(\"Mean Hazard Function\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 Percentile Distribution Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(p10, bins=30, alpha=0.5, color=\"green\", label=\"P10\", density=True)\n",
    "ax.hist(p50, bins=30, alpha=0.5, color=\"steelblue\", label=\"P50\", density=True)\n",
    "ax.hist(p90, bins=30, alpha=0.5, color=\"orange\", label=\"P90\", density=True)\n",
    "\n",
    "observed_tte = tte_true[event_true == 1.0]\n",
    "if len(observed_tte) > 0:\n",
    "    ax.hist(observed_tte, bins=30, alpha=0.4, color=\"red\",\n",
    "            label=\"Observed BT times\", density=True)\n",
    "\n",
    "ax.set_xlabel(\"Time to Breakthrough (normalized)\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_title(\"Percentile Distributions vs Observed\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Save & Export\n",
    "\n",
    "Save all plots to the `results/` directory and export the final metrics report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all standard plots via the evaluate module\n",
    "plot_training_history(history, SAVE_DIR)\n",
    "plot_predictions(model, dataset, SAVE_DIR, DEVICE)\n",
    "plot_fractional_flow_curve(model, SAVE_DIR)\n",
    "plot_survival_analysis(model, dataset, SAVE_DIR, DEVICE)\n",
    "\n",
    "# Save metrics to text file\n",
    "from pathlib import Path\n",
    "save_path = Path(SAVE_DIR)\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "with open(save_path / \"metrics.txt\", \"w\") as f:\n",
    "    f.write(\"Water Breakthrough Prediction - Evaluation Report\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    for key, value in metrics.items():\n",
    "        if isinstance(value, dict):\n",
    "            f.write(f\"\\n{key}:\\n\")\n",
    "            for k, v in value.items():\n",
    "                f.write(f\"  {k}: {v}\\n\")\n",
    "        else:\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "print(f\"\\nAll outputs saved to: {SAVE_DIR}\")\n",
    "print(f\"Model checkpoint:     {config.model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  FINAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n  Water Cut Prediction:\")\n",
    "print(f\"    MAE:  {metrics['mae']:.4f}\")\n",
    "print(f\"    RMSE: {metrics['rmse']:.4f}\")\n",
    "print(f\"    R²:   {metrics['r2']:.4f}\")\n",
    "if \"bt_f1\" in metrics:\n",
    "    print(f\"\\n  Breakthrough Detection:\")\n",
    "    print(f\"    F1:       {metrics['bt_f1']:.4f}\")\n",
    "    print(f\"    Accuracy: {metrics['bt_accuracy']:.4f}\")\n",
    "print(f\"\\n  Physics-Data Gate: {metrics['gate_mean']:.3f} (1=physics, 0=data)\")\n",
    "if \"survival_p50_mean\" in metrics:\n",
    "    print(f\"\\n  Survival Percentiles:\")\n",
    "    print(f\"    P10: {metrics['survival_p10_mean']:.4f}\")\n",
    "    print(f\"    P50: {metrics['survival_p50_mean']:.4f}\")\n",
    "    print(f\"    P90: {metrics['survival_p90_mean']:.4f}\")\n",
    "    if \"survival_calibration_80\" in metrics:\n",
    "        print(f\"    Calibration (80%): {metrics['survival_calibration_80']:.1%}\")\n",
    "print(f\"\\n  Learned Physics:\")\n",
    "p = metrics[\"physics_params\"]\n",
    "print(f\"    S_wc={p['s_wc']:.3f}  S_or={p['s_or']:.3f}  \"\n",
    "      f\"n_w={p['n_w']:.2f}  n_o={p['n_o']:.2f}  \"\n",
    "      f\"M={p['mu_w']/p['mu_o']:.3f}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}